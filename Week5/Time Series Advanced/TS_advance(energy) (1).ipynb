{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Q. 기상 실측 데이터를 토대로 태양광 발전량인 amount(2023-10-15) 값을 예측해보시오."
      ],
      "metadata": {
        "id": "H7M6mqavCdgs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UunFQBs9FaX0",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import plotly.graph_objects as go\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "pd.set_option('display.max_column', 20)\n",
        "pd.set_option('display.max_row', 100)\n",
        "\n",
        "data = pd.read_csv('/content/energy_tobigs_question.csv')\n",
        "data['time'] = pd.to_datetime(data['time'])\n",
        "\n",
        "# 피처와 타겟 변수 설정\n",
        "features = ['cloud', 'temp', 'humidity', 'ground_press', 'wind_speed', 'wind_dir', 'rain', 'snow', 'dew_point', 'vis', 'uv_idx', 'azimuth', 'elevation']\n",
        "target = 'amount'\n",
        "\n",
        "# 데이터셋 분리 (2023-10-14까지 학습, 2023-10-15 하루 예측)\n",
        "train_data = data[data['time'] < '2023-10-15'].copy()\n",
        "test_data = data[(data['time'] >= '2023-10-15') & (data['time'] < '2023-10-16')].copy()\n",
        "\n",
        "# 학습 데이터에 NaN 값 제거\n",
        "train_data = train_data.dropna()\n",
        "\n",
        "# 데이터 스케일링\n",
        "scaler_x = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "train_data.loc[:, features] = scaler_x.fit_transform(train_data[features])\n",
        "train_data.loc[:, target] = scaler_y.fit_transform(train_data[[target]])\n",
        "\n",
        "test_data.loc[:, features] = scaler_x.transform(test_data[features])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시퀀스 데이터 생성 함수 작성\n"
      ],
      "metadata": {
        "id": "dne_kc6_Fn6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서로 변환해서 텐서데이터셋을 생성하세요. (1~6 번에 내용을 채워보세요.)\n",
        "\n",
        "# 시퀀스 데이터 생성 함수\n",
        "# dataX: 시퀀스 데이터를 담은 리스트 (예: [[시퀀스1], [시퀀스2], ...])\n",
        "# dataY: 각 시퀀스에 대응하는 타겟 값 (예: 발전량)\n",
        "\n",
        "def build_dataset(time_series, seq_length):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(time_series) - seq_length):\n",
        "        dataX.append(time_series[i:i+seq_length, :-1])\n",
        "        dataY.append(time_series[i+seq_length, [-1]])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "seq_length = 24\n",
        "batch_size = 32\n",
        "\n",
        "# 학습 데이터 생성\n",
        "# trainX: 24시간의 피처 데이터\n",
        "# trainY: 그 다음 시간에 대한 발전량 값\n",
        "trainX, trainY = build_dataset(train_data[features + [target]].values, seq_length)\n",
        "\n",
        "# 텐서로 변환\n",
        "trainX_tensor = torch.tensor(trainX)\n",
        "trainY_tensor = torch.tensor(trainY)\n",
        "\n",
        "# 텐서데이터셋 생성\n",
        "train_dataset = TensorDataset(trainX_tensor, trainY_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "GkdLvF-nFrxQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습한 시계열 모델을 사용해서 예측을 해보세요 (RNN, LSTM, Transformer, Informer 중에서 선택적으로 활용)"
      ],
      "metadata": {
        "id": "LZtaJNcVFsLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 슬라이딩 윈도우 방식으로 2023-10-15의 24시간 발전량 예측해보기 (Direct Multi-step Forecast Strategy 혹은 Recursive Multi-step Forecast 등 이외의 방법론도 자유롭게 사용 가능)\n",
        "# 필요한 라이브러리 추가\n",
        "import torch.nn as nn\n",
        "\n",
        "# RNN 모델 정의\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # RNN 레이어\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "        # 출력 레이어\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 초기 hidden state\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        # RNN 레이어 통과\n",
        "        out, _ = self.rnn(x, h0)\n",
        "\n",
        "        # 마지막 시퀀스의 출력만 사용\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "input_size = len(features)  # 입력 feature의 개수\n",
        "hidden_size = 64  # RNN hidden state 크기\n",
        "output_size = 1  # 발전량 예측이므로 1\n",
        "num_layers = 2  # RNN 레이어 수\n",
        "\n",
        "# 모델 생성\n",
        "model = RNNModel(input_size, hidden_size, output_size, num_layers)\n",
        "\n",
        "# GPU 사용 여부 확인 후 모델에 적용\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# 손실 함수 및 옵티마이저 설정\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 학습\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch_X, batch_Y in train_loader:\n",
        "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
        "\n",
        "        # 모델 예측\n",
        "        outputs = model(batch_X.float())\n",
        "        loss = criterion(outputs, batch_Y.float())\n",
        "\n",
        "        # 역전파 및 가중치 업데이트\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # 에포크마다 손실 출력\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# 테스트 데이터 준비\n",
        "testX = test_data[features].values\n",
        "X_test_tensor = torch.tensor(testX, dtype=torch.float32)\n",
        "X_test_tensor = X_test_tensor.unsqueeze(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVitmLq_uG2F",
        "outputId": "e9afb99d-a901-4ae0-8323-9d13bf332e6a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.0200\n",
            "Epoch [20/100], Loss: 0.0021\n",
            "Epoch [30/100], Loss: 0.0006\n",
            "Epoch [40/100], Loss: 0.0019\n",
            "Epoch [50/100], Loss: 0.0033\n",
            "Epoch [60/100], Loss: 0.0027\n",
            "Epoch [70/100], Loss: 0.0013\n",
            "Epoch [80/100], Loss: 0.0021\n",
            "Epoch [90/100], Loss: 0.0038\n",
            "Epoch [100/100], Loss: 0.0025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2023-10-15 발전량 예측값을 predicted_amounts에 저장하고 시각화를 실행해주세요."
      ],
      "metadata": {
        "id": "GXnKhcF7Gd22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 수행 후 predicted_amounts에 저장\n",
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "# 시퀀스 데이터를 슬라이딩 윈도우 방식으로 사용하여 예측\n",
        "with torch.no_grad():\n",
        "    input_seq = X_test_tensor[:seq_length].unsqueeze(0)  # 24시간의 입력 시퀀스\n",
        "    input_seq = input_seq.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    for _ in range(24):  # 24시간 발전량 예측\n",
        "        predicted_output = model(input_seq)\n",
        "        predictions.append(predicted_output.item())\n",
        "\n",
        "        # 슬라이딩 윈도우: 예측 결과를 다음 시퀀스의 입력으로 사용\n",
        "        next_input = torch.cat((input_seq[:, 1:, :], predicted_output.unsqueeze(0).unsqueeze(2)), dim=1)\n",
        "        input_seq = next_input\n",
        "\n",
        "# 예측 결과를 scaling 복원 후 predicted_amounts로 저장\n",
        "predicted_amounts = scaler_y.inverse_transform(np.array(predictions).reshape(-1, 1)).flatten()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "c96CTbczP_gu",
        "outputId": "8489a221-1073-4470-84f1-f13f0dcb8114"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "RNN: Expected input to be 2D or 3D, got 4D tensor instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-86ff92c6af8e>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 24시간 발전량 예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpredicted_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d07b646725cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# RNN 레이어 통과\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# 마지막 시퀀스의 출력만 사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"RNN: Expected input to be 2D or 3D, got {input.dim()}D tensor instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mis_batched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mbatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: RNN: Expected input to be 2D or 3D, got 4D tensor instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화\n",
        "fig = go.Figure()\n",
        "\n",
        "# 실제 발전량 시각화\n",
        "fig.add_trace(go.Scatter(x=data['time'], y=data['amount'],\n",
        "                         mode='lines', name='Actual Amount'))\n",
        "\n",
        "# 예측된 발전량 시각화 (2023-10-15의 24시간 동안의 예측)\n",
        "fig.add_trace(go.Scatter(x=test_data['time'], y=predicted_amounts,\n",
        "                         mode='lines', name='Predicted Amount', line=dict(dash='dot', color='red')))\n",
        "\n",
        "# 레이아웃 설정\n",
        "fig.update_layout(title='2023-10-15 24시간 발전량 예측',\n",
        "                  xaxis_title='시간',\n",
        "                  yaxis_title='발전량 (kWh)')\n",
        "\n",
        "# 그래프 출력\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "85a5LYliGbci",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "9e5e96de-1420-4ca0-8581-ab40c3ba9231"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'predicted_amounts' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-378a3836d226>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 예측된 발전량 시각화 (2023-10-15의 24시간 동안의 예측)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m fig.add_trace(go.Scatter(x=test_data['time'], y=predicted_amounts,\n\u001b[0m\u001b[1;32m     10\u001b[0m                          mode='lines', name='Predicted Amount', line=dict(dash='dot', color='red')))\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'predicted_amounts' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정답을 적어주세요."
      ],
      "metadata": {
        "id": "i4qc4G_sIPYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측된 24시간 발전량 출력\n",
        "print(f'2023-10-15 예측 발전량 (24시간): {predicted_amounts} kWh')"
      ],
      "metadata": {
        "id": "Oxu_nPKAIRiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ngKvGGwZIFLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (필수) Informer모델은 transformer 모델의 어떤 부분을 개선하고자 했나요? (차이점을 중심으로 서술)"
      ],
      "metadata": {
        "id": "uG2WPZYKEOvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. Self-Attention의 계산효율성\n",
        "- Transformer는 시퀀스 길이가 길어질수록 계산 비용이 매우 커짐 반면에, 인포머는 중요한 쌍에만 집중하기 때문에 효율적인 계산이 가능함\n",
        "2. Memory 문제 개선\n",
        "- 트랜스포머는 대규모 메모리 사용이 발생하나 인포머는 불필요한 키-쿼리간 상호작용을 줄이기 때문에 메모리 사용량도 크게 줄임\n",
        "3. 긴 시퀀스에서의 전반적인 정보 흐름 문제\n",
        "4. 확장성"
      ],
      "metadata": {
        "id": "cGKQnbBeEfZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (필수) 모델링 해석"
      ],
      "metadata": {
        "id": "bxrmj2bGGpKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 선택했다면 왜 선택했는지 본인만의 근거를 정리해주세요.\n",
        "# 더 나아가 파라미터 선택의 기준이 있었다면 좋습니다.\n",
        "코드가 안돌아가요..."
      ],
      "metadata": {
        "id": "uXJxcNijGtVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (선택) 데이터 해석"
      ],
      "metadata": {
        "id": "AWdkUtoyHwxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋을 보고 느낀 생각이나 본인만의 논리 전개 방식을 정리해주세요.\n",
        "# 전처리를 했다면 해당 전처리를 왜 했는지, 파생변수를 생성했다면 왜 만들었는지 등"
      ],
      "metadata": {
        "id": "dLm_wa71Hy1M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}