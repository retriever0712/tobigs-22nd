{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**BERT 모델 불러오기**"
      ],
      "metadata": {
        "id": "qpuN697Kq53F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRlFpOqXqyBg"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "\n",
        "# 1. BERT 토크나이저와 모델을 로드\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer의 내장함수를 이용해 특수 토큰을 불러오는 함수를 작성해주세요\n",
        "\n",
        "tokenizer.special_tokens_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgK_7wUdusTv",
        "outputId": "18e3c894-cafd-42ee-f23c-e5881abcf158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'unk_token': '[UNK]',\n",
              " 'sep_token': '[SEP]',\n",
              " 'pad_token': '[PAD]',\n",
              " 'cls_token': '[CLS]',\n",
              " 'mask_token': '[MASK]'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.BERT Tokenizer의 특수 토큰**\n",
        "\n",
        "아래 코드에서 특수 토큰을 불러오는 함수를 작성하고 각 토큰이 무엇을 의미하는지 적어주세요\n",
        "\n",
        "- [UNK] : 미리 사전에 등록되지 않은 단어를 처리하기 위한 토큰\n",
        "- [SEP] : 두 문장의 사이를 구분하기 위한 토큰\n",
        "- [PAD] : 문장의 길이가 모델이 정해준 길이와 맞지 않을 때 이를 맞춰주기 위한 토큰\n",
        "- [CLS] : 문장의 시작 부호를 담당하고 동시에 마지막에 문맥에 대한 정보를 포함함으로써 분류(감정, category)에 사용하는 토큰\n",
        "- [MASK] : 특정 단어를 예측하고자 하는 업무를 수행할 때 그 단어를 가려 예측하도록 하기 위한 토큰"
      ],
      "metadata": {
        "id": "XEFeQrU0us5V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenizer를 이용해 문장을 토큰화**\n",
        "\n",
        "토큰화를 통해 문자를 숫자로 변환하여 컴퓨터가 이해할 수 있도록 한다."
      ],
      "metadata": {
        "id": "1apIxfDpwu-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 문장\n",
        "sentence = \"Hello, this is a sentence for tokenization.\"\n",
        "\n",
        "# 문장 토큰화 및\n",
        "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "\n",
        "# 토큰 ID를 다시 토큰으로 변환\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0].tolist())  # 텐서를 리스트로 변환\n",
        "\n",
        "print(\"Token IDs:\", inputs['input_ids'])\n",
        "print(\"Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuR9uq4mtsHg",
        "outputId": "b12b39b6-89df-474c-fc8a-99d767a73e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs: tensor([[  101,  7592,  1010,  2023,  2003,  1037,  6251,  2005, 19204,  3989,\n",
            "          1012,   102]])\n",
            "Tokens: ['[CLS]', 'hello', ',', 'this', 'is', 'a', 'sentence', 'for', 'token', '##ization', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. 토큰화**\n",
        "토큰화 이후에 [CLS] 토큰과 [SEP] 토큰이 추가된 이유를 작성하세요\n",
        "\n",
        "- [CLS] 토큰이 추가된 이유 : 문장의 시작을 알리고 문장의 모든 의미를 함축하여 특정 분류문제를 수행할 수 있도록 함\n",
        "- [SEP] 토큰이 추가된 이유 : 문장과 문장 사이를 구분하여 문맥을 더 잘 파악하도록 하기 위함"
      ],
      "metadata": {
        "id": "BIxC3FkbxC0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**감성 분류를 위한 사전 학습된 BERT 모델을 이용해 감성분류하기**"
      ],
      "metadata": {
        "id": "lSVyydIqOIQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertForSequenceClassification\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "# 감성 분류를 위한 사전 학습된 모델\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "sioGxOIFOGcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence에 대해 BERT를 이용해 감성분류 하는 함수\n",
        "def sentiment_analysis(sentence):\n",
        "\n",
        "    ############### EDIT###############\n",
        "    'sentiment analysis 구현'\n",
        "\n",
        "    model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"  # BERT 감정 분석 모델\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    model = BertForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "    # 2. 입력 문장 토큰화\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "    # 3. 모델 예측 수행\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # 4. 소프트맥스 함수로 확률 계산\n",
        "    probs = torch.softmax(outputs.logits, dim=1)\n",
        "\n",
        "    # 5. 확률 리스트로 변환\n",
        "    probs_list = probs.squeeze().tolist()\n",
        "\n",
        "    ###################################\n",
        "\n",
        "    # 클래스 레이블 정의\n",
        "    class_label = ['매우 부정적', '부정적', '중립적', '긍정적', '매우 긍정적']\n",
        "\n",
        "    # 결과 출력 (소수점 2자리로 출력)\n",
        "    for i, prob in enumerate(probs_list):\n",
        "        print(f\"{class_label[i]}일 확률: {prob:.2f}\")"
      ],
      "metadata": {
        "id": "Eoh7OtBuO-j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. BERT를 이용하여 각각 class에 맞는 sentence 작성해보기**\n",
        "\n",
        "1. 매우 부정적인 문장을 작성해서 매우 부정적에 대한 확률을 최대화 해보세요\n",
        "2. 부정적인 문장을 작성해서 매우 부정적에 대한 확률을 최대화 해보세요\n",
        "3. 중립적인 문장을 작성해서 매우 부정적에 대한 확률을 최대화 해보세요\n",
        "4. 긍정적인 문장을 작성해서 매우 부정적에 대한 확률을 최대화 해보세요\n",
        "5. 매우 긍정적인 문장을 작성해서 매우 부정적에 대한 확률을 최대화 해보세요"
      ],
      "metadata": {
        "id": "KKeBYa8ZPT__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 매우 부정적인 문장 작성\n",
        "sentence = \"This is the worst movie I have ever seen. It was a complete waste of time\"\n",
        "\n",
        "# 감성분석 수행\n",
        "sentiment_analysis(sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5Txn2BNmLUTx",
        "outputId": "8f387e83-47be-4eb5-afa4-8d25f0637d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "매우 부정적일 확률: 0.96\n",
            "부정적일 확률: 0.04\n",
            "중립적일 확률: 0.00\n",
            "긍정적일 확률: 0.00\n",
            "매우 긍정적일 확률: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 부정적인 문장 작성\n",
        "sentence = \"I do not like this movie. It is quite boring. Also its main plot is not my type\"\n",
        "\n",
        "# 감성분석 수행\n",
        "sentiment_analysis(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSRqPmBGMK67",
        "outputId": "2786f031-f009-40c2-c969-44d9325052c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "매우 부정적일 확률: 0.36\n",
            "부정적일 확률: 0.58\n",
            "중립적일 확률: 0.06\n",
            "긍정적일 확률: 0.00\n",
            "매우 긍정적일 확률: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중립적 문장 작성\n",
        "sentence = \"The movie was okay. It had some good moments, but overall it wasn't particularly memorable.\"\n",
        "\n",
        "# 감성분석 수행\n",
        "sentiment_analysis(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGrfIJyyPMpp",
        "outputId": "334bc312-7553-4293-8552-27b8a62ccc47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "매우 부정적일 확률: 0.00\n",
            "부정적일 확률: 0.09\n",
            "중립적일 확률: 0.86\n",
            "긍정적일 확률: 0.04\n",
            "매우 긍정적일 확률: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 긍정적 문장 작성\n",
        "sentence = \"I like this movie. It was not bad and not boring. It was nice try.\"\n",
        "\n",
        "# 감성분석 수행\n",
        "sentiment_analysis(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfNX8QgnPNB2",
        "outputId": "f2fbc366-f3ab-4c72-c9d8-988e7649885c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "매우 부정적일 확률: 0.00\n",
            "부정적일 확률: 0.00\n",
            "중립적일 확률: 0.07\n",
            "긍정적일 확률: 0.60\n",
            "매우 긍정적일 확률: 0.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 매우 긍정적인 문장 작성\n",
        "sentence = \"This is one of the best movies I've ever seen! Everything about it was perfect, from the acting to the story.\"\n",
        "\n",
        "# 감성분석 수행\n",
        "sentiment_analysis(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVF2Q7EkPNRm",
        "outputId": "29abff7a-da80-4e08-9cfd-98aadd1288fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "매우 부정적일 확률: 0.00\n",
            "부정적일 확률: 0.00\n",
            "중립적일 확률: 0.00\n",
            "긍정적일 확률: 0.02\n",
            "매우 긍정적일 확률: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. BERT의 감성 분류 기준에 대해 생각을 적어보기**\n",
        "\n",
        "\n",
        "BERT가 어떤 요소에 따라 감성 분류 기준을 나누는지에 대해 적어보세요\n",
        "\n",
        "내가 생각하는 분류 기준 : 먼저 특정 token이 어떠한 감정이 담긴 문장에서 많이 사용됐는지에 주목할 것 같다. 어떤 단어가 어떤 감정으로 많이 나타나는지 파악하여 단어 자체의 감정을 우선 분석할 필요가 있어 보인다. 이후 문맥을 파악하여 특정한 감정을 반전시킬만한 다른 단어가 존재하는지를 고려하여 문장 전체의 담긴 감정을 파악할 것으로 보인다. 예를 들어 love가 있더라도 주변에 not이 존재한다면 해당 문장을 부정적으로 격하시키는 등의 방식이 존재할 것으로 생각된다."
      ],
      "metadata": {
        "id": "RL8Yh-tKRmxN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_JUFFpLKP9Bd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}