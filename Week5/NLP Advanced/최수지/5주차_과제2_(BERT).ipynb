{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**BERT 모델 불러오기**"
      ],
      "metadata": {
        "id": "qpuN697Kq53F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "vRlFpOqXqyBg"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "\n",
        "# 1. BERT 토크나이저와 모델을 로드\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.BERT Tokenizer의 특수 토큰**\n",
        "\n",
        "아래 코드에서 특수 토큰을 불러오는 함수를 작성하고 각 토큰이 무엇을 의미하는지 적어주세요\n",
        "\n",
        "- [UNK] : 알 수 없는 단어에 대한 토큰\n",
        "- [SEP] : 문장 구분 토큰\n",
        "- [PAD] : 패딩 토큰\n",
        "- [CLS] : 문장 시작을 의미하는 토큰\n",
        "- [MASK] : 마스킹된 단어에 대한 토큰"
      ],
      "metadata": {
        "id": "XEFeQrU0us5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer의 내장함수를 이용해 특수 토큰을 불러오는 함수를 작성해주세요\n",
        "\n",
        "def get_special_tokens(tokenizer):\n",
        "    special_tokens = {\n",
        "        'unk_token': tokenizer.unk_token,\n",
        "        'sep_token': tokenizer.sep_token,\n",
        "        'pad_token': tokenizer.pad_token,\n",
        "        'cls_token': tokenizer.cls_token,\n",
        "        'mask_token': tokenizer.mask_token\n",
        "    }\n",
        "    return special_tokens\n",
        "\n",
        "special_tokens = get_special_tokens(tokenizer)\n",
        "print(special_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgK_7wUdusTv",
        "outputId": "a0a23182-0a4b-4cf9-a464-01ba02189dde"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenizer를 이용해 문장을 토큰화**\n",
        "\n",
        "토큰화를 통해 문자를 숫자로 변환하여 컴퓨터가 이해할 수 있도록 한다."
      ],
      "metadata": {
        "id": "1apIxfDpwu-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 문장\n",
        "sentence = \"Hello, this is a sentence for tokenization.\"\n",
        "\n",
        "# 문장 토큰화 및\n",
        "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
        "\n",
        "# 토큰 ID를 다시 토큰으로 변환\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0].tolist())  # 텐서를 리스트로 변환\n",
        "\n",
        "print(\"Token IDs:\", inputs['input_ids'])\n",
        "print(\"Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuR9uq4mtsHg",
        "outputId": "a3b3edc1-7cf7-463a-b42e-57438bd836a6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs: tensor([[  101,  7592,  1010,  2023,  2003,  1037,  6251,  2005, 19204,  3989,\n",
            "          1012,   102]])\n",
            "Tokens: ['[CLS]', 'hello', ',', 'this', 'is', 'a', 'sentence', 'for', 'token', '##ization', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. 토큰화**\n",
        "토큰화 이후에 [CLS] 토큰과 [SEP] 토큰이 추가된 이유를 작성하세요\n",
        "\n",
        "- [CLS] 토큰이 추가된 이유 : [CLS] 토큰은 문장의 시작을 나타내기 위해 사용된다. 따라서 입력 시퀀스의 첫 번째에 항상 추가되기 때문에 추가되었다.\n",
        "- [SEP] 토큰이 추가된 이유 : [SEP] 토큰은 두 문장 간의 구분을 나타내기 위해 사용된다. 또한 문장 쌍 태스크가 아닌 경우에도, 입력 시퀀스의 끝을 나타내는 데 사용되기 때문에 추가되었다."
      ],
      "metadata": {
        "id": "BIxC3FkbxC0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**감성 분류를 위한 사전 학습된 BERT 모델을 이용해 감성분류하기**"
      ],
      "metadata": {
        "id": "lSVyydIqOIQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertForSequenceClassification\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "# 감성 분류를 위한 사전 학습된 모델\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "model = BertForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "sioGxOIFOGcp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence에 대해 BERT를 이용해 감성분류 하는 함수\n",
        "def sentiment_analysis(sentence):\n",
        "\n",
        "    encoding = tokenizer(sentence, max_length=512, truncation=True, padding='max_length', return_tensors='pt')\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for k,v in encoding.items():\n",
        "        encoding[k] = v.to(device)\n",
        "\n",
        "    outputs = model(**encoding)\n",
        "\n",
        "    prediction_probs = softmax(outputs.logits, dim=1)\n",
        "    probs_list = prediction_probs.squeeze().tolist()\n",
        "\n",
        "    # 클래스 레이블 정의\n",
        "    class_label = ['매우 부정적', '부정적', '중립적', '긍정적', '매우 긍정적']\n",
        "\n",
        "    # 결과 출력 (소수점 2자리로 출력)\n",
        "    for i, prob in enumerate(probs_list):\n",
        "        print(f\"{class_label[i]}일 확률: {prob:.2f}\")"
      ],
      "metadata": {
        "id": "Eoh7OtBuO-j_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. BERT를 이용하여 각각 class에 맞는 sentence 작성해보기**\n",
        "\n",
        "1. 매우 부정적인 문장을 작성해서 매우 부정적에 대한 확률을 최대화 해보세요\n",
        "2. 부정적인 문장을 작성해서 매우 부정적에 대한 확률을 최대화 해보세요\n",
        "3. 중립적인 문장을 작성해서 매우 부정적에 대한 확률을 최대화 해보세요\n",
        "4. 긍정적인 문장을 작성해서 매우 부정적에 대한 확률을 최대화 해보세요\n",
        "5. 매우 긍정적인 문장을 작성해서 매우 부정적에 대한 확률을 최대화 해보세요"
      ],
      "metadata": {
        "id": "KKeBYa8ZPT__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 매우 부정적인 문장 작성\n",
        "sentence = \"This is an absolute catastrophe. Everything about this experience has been a nightmare from start to finish. The service was a complete disaster, the product is worthless and malfunctioning, and I am left feeling utterly betrayed and infuriated. I can't believe how horrendous this has been; it's the worst possible outcome imaginable.\"\n",
        "\n",
        "# 감성분석 수행\n",
        "sentiment_analysis(sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Txn2BNmLUTx",
        "outputId": "14518456-1c2b-4662-e862-366fce683b69"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "매우 부정적일 확률: 0.59\n",
            "부정적일 확률: 0.25\n",
            "중립적일 확률: 0.11\n",
            "긍정적일 확률: 0.03\n",
            "매우 긍정적일 확률: 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 부정적인 문장 작성\n",
        "sentence = \"The product was disappointing and didn't work as intended. While it was somewhat functional, it failed to meet my expectations and left me dissatisfied.\"\n",
        "\n",
        "# 감성분석 수행\n",
        "sentiment_analysis(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSRqPmBGMK67",
        "outputId": "2841b427-8411-4cd6-ca2a-f73a51c4e0b9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "매우 부정적일 확률: 0.27\n",
            "부정적일 확률: 0.31\n",
            "중립적일 확률: 0.28\n",
            "긍정적일 확률: 0.10\n",
            "매우 긍정적일 확률: 0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중립적 문장 작성\n",
        "sentence = \"He has a job in the medical field.\"\n",
        "\n",
        "# 감성분석 수행\n",
        "sentiment_analysis(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGrfIJyyPMpp",
        "outputId": "e063dfdf-1165-4322-f773-8b146521170f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "매우 부정적일 확률: 0.06\n",
            "부정적일 확률: 0.12\n",
            "중립적일 확률: 0.33\n",
            "긍정적일 확률: 0.30\n",
            "매우 긍정적일 확률: 0.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 긍정적 문장 작성\n",
        "sentence = \"Being out feels good.\"\n",
        "\n",
        "# 감성분석 수행\n",
        "sentiment_analysis(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfNX8QgnPNB2",
        "outputId": "bcd75dc0-679c-4761-8388-b5728cef0e46"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "매우 부정적일 확률: 0.11\n",
            "부정적일 확률: 0.15\n",
            "중립적일 확률: 0.26\n",
            "긍정적일 확률: 0.27\n",
            "매우 긍정적일 확률: 0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 매우 긍정적인 문장 작성\n",
        "sentence = \"She feels happy because the weather is so nice.\"\n",
        "\n",
        "# 감성분석 수행\n",
        "sentiment_analysis(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVF2Q7EkPNRm",
        "outputId": "4ab82a56-d8a8-49a9-e520-6e2d9deae738"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "매우 부정적일 확률: 0.08\n",
            "부정적일 확률: 0.09\n",
            "중립적일 확률: 0.19\n",
            "긍정적일 확률: 0.28\n",
            "매우 긍정적일 확률: 0.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. BERT의 감성 분류 기준에 대해 생각을 적어보기**\n",
        "\n",
        "\n",
        "BERT가 어떤 요소에 따라 감성 분류 기준을 나누는지에 대해 적어보세요\n",
        "\n",
        "내가 생각하는 분류 기준 :\n",
        "\n",
        "나는 BERT가 주로 문맥적 의미와 단어 간의 관계를 기반으로 감성을 분류한다고 생각한다. BERT는 사전 학습된 언어 모델로서, 문장 내 단어들의 의미를 이해하기 위해 양방향 문맥을 활용한다. 문장의 모든 단어가 문맥에서 어떻게 사용되는지를 고려하여 감성 분류를 수행하는 것이다. 이러한 접근 방식은 문장의 감정을 판단하는 데 중요한 요소인 감정적 뉘앙스, 문맥적 상관관계, 그리고 문장 내 단어들의 상호작용을 보다 정교하게 파악할 수 있게 한다."
      ],
      "metadata": {
        "id": "RL8Yh-tKRmxN"
      }
    }
  ]
}