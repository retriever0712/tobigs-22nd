{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WW4t3iCYKuy"
   },
   "source": [
    "## 과제 1\n",
    "\n",
    "### **Q. 각 모델이 충족하는 속성에 대해 아래 표를 O/X로 채워주세요.**\n",
    "\n",
    "📍5번째 속성은 **LSTM 기준으로** O/X 여부 판단해주세요 ! <br>\n",
    "📍정답은 과제 마감 다음날 (9월 11일 수요일)에 **노션-정규세션-NLP basic**에 업로드 예정\n",
    "\n",
    "\n",
    "> #### **속성 설명**\n",
    "1. Order matters : 입력 시퀀스의 순서 중요 여부\n",
    "2. Variable Length : 고정된 길이가 아닌 다양한 길이의 시퀀스를 처리할 수 있는지 여부\n",
    "3. Differentiable : 미분가능\n",
    "4. Pairwise encoding : 두 단어 사이의 관계를 표현\n",
    "5. Preserves long-term : 장기적인 의존성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "paUeOH0OYNU0"
   },
   "source": [
    "|               | N-gram | RNN   | LSTM  | Transformer |\n",
    "|:-------------:|:------:|:-----:|:-----:|:-----------:|\n",
    "| Order matters |        |     |      | O           |\n",
    "| Variable length |      |     |      | O           |\n",
    "| Differentiable |       |     |      | O           |\n",
    "| Pairwise encoding |    |     |      | O           |\n",
    "| Preserves long-term |  |     |      | O           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14MthA8WYQev"
   },
   "source": [
    "## 과제 2\n",
    "\n",
    "\n",
    "### 목표 : 독일어를 영어로 번역하는 모델 만들기\n",
    "독일어 문장을 입력하면 영어로 번역해주는 모델을 seq2seq로 구현해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PbwGzED6TIV"
   },
   "outputs": [],
   "source": [
    "!pip install -U torchtext==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPKSSHzQ6Uoh"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en\n",
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJWiAS2yWutF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import spacy\n",
    "from torchtext.datasets import TranslationDataset\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHmIKputmJfU"
   },
   "source": [
    "### Tokenizers\n",
    "\n",
    "- 문장의 토큰화, 태깅 등의 전처리를 수행하기 위해 `spaCy` 라이브러리에서 영어와 독일어 전처리 모듈을 설치해줍니다.\n",
    "- 두 언어의 문장이 주어졌기 때문에 영어와 독일어 각각에 대해 전처리해주어야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7ZtI5IXm7EG"
   },
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "co1TC8yv7yrX"
   },
   "outputs": [],
   "source": [
    "# 예시\n",
    "result = spacy_en.tokenizer(\"I am a student.\")\n",
    "\n",
    "for i, token in enumerate(result):\n",
    "    print(f\"인덱스 {i}: {token.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEGmP9Uk8gQG"
   },
   "source": [
    "필드(field) 라이브러리를 이용해 데이터셋에 대한 구체적인 전처리 내용을 명시해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMjoI1XE7tGF"
   },
   "outputs": [],
   "source": [
    "#===================================================\n",
    "# 💡 토큰화 결과가 list로 반환될 수 있도록 return 결과값을 채워주세요\n",
    "# seq2sxeq 논문에 의하면, input 단어의 순서를 바꾸면 최적화가 더 쉬워져 성능이 좋아진다고 합니다.\n",
    "# 💡 독일어 토큰화 결과가 역순으로 return될 수 있도록 반영해주세요!\n",
    "#===================================================\n",
    "def tokenize_de(text):\n",
    "    return [token.text for token in spacy_de.tokenizer(text)][::-1]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [token.text for token in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3wGw1nPnpMd"
   },
   "source": [
    "필드(field) 라이브러리를 이용해 데이터셋에 대한 구체적인 전처리 내용을 명시해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubKI59GPpQ1f"
   },
   "outputs": [],
   "source": [
    "# 독일어\n",
    "SRC = Field(tokenize= tokenize_de, init_token = '<sos>', eos_token = '<eos>', lower = True)\n",
    "# 영어\n",
    "TRG = Field(tokenize= tokenize_en, init_token = '<sos>', eos_token = '<eos>', lower = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_ccI6_-8hR3"
   },
   "source": [
    "### 데이터 불러오기\n",
    "\n",
    "대표적인 영어-독어 번역 데이터셋 Multi30k을 불러옵니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLA5kXAAf2uw"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/multi30k/dataset.git\n",
    "\n",
    "# 압축해제\n",
    "!gunzip /content/dataset/data/task1/raw/train.de.gz\n",
    "!gunzip /content/dataset/data/task1/raw/train.en.gz\n",
    "!gunzip /content/dataset/data/task1/raw/val.de.gz\n",
    "!gunzip /content/dataset/data/task1/raw/val.en.gz\n",
    "!gunzip /content/dataset/data/task1/raw/test_2018_flickr.de.gz\n",
    "!gunzip /content/dataset/data/task1/raw/test_2018_flickr.en.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0JchGVU91Q5"
   },
   "outputs": [],
   "source": [
    "data_path = '/content/dataset/data/task1/raw/'\n",
    "\n",
    "train_data = TranslationDataset(path=data_path, exts=('train.de', 'train.en'), fields=(SRC, TRG) )\n",
    "val_data = TranslationDataset(path=data_path, exts=('val.de', 'val.en'), fields=(SRC, TRG) )\n",
    "test_data = TranslationDataset(path=data_path, exts=('test_2018_flickr.de', 'test_2018_flickr.en'), fields=(SRC, TRG) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1724602161494,
     "user": {
      "displayName": "차민재",
      "userId": "05174396098945723154"
     },
     "user_tz": -540
    },
    "id": "qxLylN1y-urW",
    "outputId": "62447416-c1f5-48c5-dec7-4c438c67a7f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터셋(training dataset) 크기: 29000개\n",
      "평가 데이터셋(validation dataset) 크기: 1014개\n",
      "테스트 데이터셋(testing dataset) 크기: 1071개\n"
     ]
    }
   ],
   "source": [
    "print(f\"학습 데이터셋(training dataset) 크기: {len(train_data.examples)}개\")\n",
    "print(f\"평가 데이터셋(validation dataset) 크기: {len(val_data.examples)}개\")\n",
    "print(f\"테스트 데이터셋(testing dataset) 크기: {len(test_data.examples)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1724602163967,
     "user": {
      "displayName": "차민재",
      "userId": "05174396098945723154"
     },
     "user_tz": -540
    },
    "id": "Rpt6l_Xd_AQX",
    "outputId": "f8d29c4a-bef3-4d61-8175-fc08ca298369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': ['.', 'büsche', 'vieler', 'nähe', 'der', 'in', 'freien', 'im', 'sind', 'männer', 'weiße', 'junge', 'zwei'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n",
      "{'src': ['.', 'antriebsradsystem', 'ein', 'bedienen', 'schutzhelmen', 'mit', 'männer', 'mehrere'], 'trg': ['several', 'men', 'in', 'hard', 'hats', 'are', 'operating', 'a', 'giant', 'pulley', 'system', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))\n",
    "print(vars(train_data.examples[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNoigj40AD_0"
   },
   "source": [
    "- `build_vocab`함수를 이용하여 영어와 독일어의 단어 사전을 생성해줍니다. 이를 통해 각 token이 indexing됩니다\n",
    "- 단, vocabulary는 훈련 데이터셋에 대해서만 만들어져야 합니다.\n",
    "- `min_freq`를 사용하여 최소 2번 이상 나오는 단어들만 사전에 포함되도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TfK-pAr_ApLP"
   },
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KyaA5P0Mrqaa"
   },
   "outputs": [],
   "source": [
    "print(TRG.vocab.stoi[\"abcabc\"]) # 없는 단어: 0\n",
    "print(TRG.vocab.stoi[TRG.pad_token]) # 패딩(padding): 1\n",
    "print(TRG.vocab.stoi[\"\"]) # : 0\n",
    "print(TRG.vocab.stoi[\"\"]) # : 0\n",
    "print(TRG.vocab.stoi[\"hello\"])\n",
    "print(TRG.vocab.stoi[\"world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmHXb1phBXJN"
   },
   "source": [
    "- 시퀀스 데이터는 각 문장의 길이가 다를 수 있습니다.\n",
    "- `BucketIterator는` 유사한 길이를 가진 샘플들을 같은 배치에 묶어주는 역할을 하기 때문에, 고정된 길이로 맞추기 위한 패딩의 양을 최소화할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uazI6xuv8rDH"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, val_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z154iai8Czsr"
   },
   "source": [
    "- 첫 번째 배치를 출력한 결과, [sequence length, batch size]라는 tensor가 생성됩니다\n",
    "- `sequence length`는 해당 배치 내에서 가장 긴 문장의 길이를 의미하며, 이보다 짧은 문장은 <pad> token으로 채워집니다.\n",
    "- 편의상 transpose한 뒤, 첫 번째와 두 번째 문장의 텐서를 출력하면, 특정 단어에 대응하는 인덱스가 출력되는 것을 알 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3r-eReL8rwm_"
   },
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_iterator):\n",
    "    src = batch.src\n",
    "    trg = batch.trg\n",
    "\n",
    "    print(f\"첫 번째 배치의 text 크기: {src.shape}\")\n",
    "    src = src.transpose(1,0)\n",
    "    print(src[0])\n",
    "    print(src[1])\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51xSGy35XLvG"
   },
   "source": [
    "### Building the Seq2Seq with LSTM Model\n",
    "\n",
    "- seq2seq 이해를 위한 과제이니, 아래를 참고하여 작성해도 무방합니다 :)\n",
    "\n",
    "\n",
    "https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/Sequence_to_Sequence_with_LSTM_Tutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9WWS97vYnSb"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtpU_ZjeYNEZ"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, p):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "        #=========================================#\n",
    "        # 💡아래줄에 embedding과 multi-layer LSTM 부분을 채워주세요 (dropout 포함)\n",
    "        #=========================================#\n",
    "        self.embedding = input_dim, emb_dim\n",
    "        self.rnn = nn.LSTM(embed_dim, hid_dim, n_layers, dropout=p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = [x length, batch size]\n",
    "        embedding = self.dropout(self.embedding(x))  # embedding = [x length, batch size, emb size]\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedding)\n",
    "\n",
    "        # hidden = [n layers, batch size, hid dim]\n",
    "        # cell = [n layer, batch size, hid dim]\n",
    "        # outputs = [src len, batch size, hid dim]\n",
    "\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrQoLPg-Ype1"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOVQfminYknh"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, p):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "        #=========================================#\n",
    "        # 💡아래 코드를 채워주고, 각각 어떤 역할을 하는지 주석으로 간단히 설명해주세요\n",
    "        #\n",
    "        #=========================================#\n",
    "        self.embedding = nn.Embedding(output_dim, embed_dim)\n",
    "        #특정 차원의 임베딩으로 매핑함.\n",
    "        self.rnn = nn.LSTM(embed_dim, hid_dim, n_layers, dropout=p)\n",
    "        #LSTM은 RNN의 단점이었던 장기 의존성 문제를 해결하고, 다음 단어를 예측하는데 도움을 줌.\n",
    "        self.fc = nn.Linear(hid_dim, output_dim)\n",
    "        #LSTM으로부터 나온 히든 상태를 받아서 최종 출력으로 변환한다. \n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "\n",
    "        # 현재 input 형태 = [batch size]\n",
    "        # Decoder는 한번에 하나의 토큰만 처리하도록 sequence length = 1이 되어야 합니다\n",
    "        input = input.unsqueeze(0)\n",
    "\n",
    "        embedding = self.dropout(self.embedding(input))\n",
    "\n",
    "        #=========================================#\n",
    "        # 💡self.rnn() 괄호 안 부분을 채워주세요\n",
    "        #=========================================#\n",
    "        output, (hidden, cell) = self.rnn(embedding, (hidden, cell)\n",
    "\n",
    "        prediction = self.fc(output.squeeze(0))  #prediction = [batch size, output dim]\n",
    "\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNsTqRamcfPg"
   },
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ik28Umx6gAPW"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "\n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        #=========================================#\n",
    "        # 💡trg를 사용하여 decoder에 입력할 첫번째 input을 설정해주세요\n",
    "        #=========================================#\n",
    "        input = trg[0, :]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "\n",
    "            outputs[t] = output\n",
    "\n",
    "            # predictions들 중에 가장 잘 예측된 token 추출\n",
    "            best_guess = output.argmax(1) # [batch size]\n",
    "\n",
    "            input = trg[t] if random.random() < teacher_forcing_ratio else best_guess\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfKrIZ63jkVF"
   },
   "source": [
    "### **Q. 위 코드에서는 매 시점마다 확률이 가장 높은 다음 단어를 선택하는 Greedy decoding  방식이 사용됩니다. 이런 방법을 채택할 경우 발생할 수 있는 문제점은 무엇일지 작성해주세요.**\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# predictions들 중에 가장 잘 예측된 token 추출\n",
    "best_guess = output.argmax(1) # [batch size]\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "➡️ 각 시점에서 가장 높은 확률을 택하기 때문에, 단기적으로는 확률이 높아보일 수 있어도, 장기적으로 보면 문맥이 어색해질 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHk36-bkh055"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xj33q4Izh3aB"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoFprkiyh5vm"
   },
   "source": [
    "모델 초기 가중치 값은 논문의 내용대로 U(−0.08,0.08)의 연속균등분포로부터 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-oLZ0jXyh4zG"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpKWiiBIF5NA"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veJrgUHBjRVa"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDfEPQUwFvVG"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0fOgC3jc8K4"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OCHWUhmGORD"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0VHYyZLjFO2"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 3\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCou2VSKVz64"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/content/seq2seq-lstm-model.pt'))\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPO048WnZCYZh+CX7AzYDsd",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
