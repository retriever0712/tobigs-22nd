{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 과제 1\n","\n","### **Q. 각 모델이 충족하는 속성에 대해 아래 표를 O/X로 채워주세요.**\n","\n","📍5번째 속성은 **LSTM 기준으로** O/X 여부 판단해주세요 ! <br>\n","📍정답은 과제 마감 다음날 (9월 11일 수요일)에 **노션-정규세션-NLP basic**에 업로드 예정\n","\n","\n","> #### **속성 설명**\n","1. Order matters : 입력 시퀀스의 순서 중요 여부\n","2. Variable Length : 고정된 길이가 아닌 다양한 길이의 시퀀스를 처리할 수 있는지 여부\n","3. Differentiable : 미분가능\n","4. Pairwise encoding : 두 단어 사이의 관계를 표현\n","5. Preserves long-term : 장기적인 의존성\n"],"metadata":{"id":"9WW4t3iCYKuy"}},{"cell_type":"markdown","source":["|               | N-gram | RNN   | LSTM  | Transformer |\n","|:-------------:|:------:|:-----:|:-----:|:-----------:|\n","| Order matters | 0       |    0 |  0    | O           |\n","| Variable length | X      |  0   |  0    | O           |\n","| Differentiable | X      |  0   |    0  | O           |\n","| Pairwise encoding | X   |   X  |     X | O           |\n","| Preserves long-term | X  | X    |     0 | O           |\n"],"metadata":{"id":"paUeOH0OYNU0"}},{"cell_type":"markdown","source":["## 과제 2\n","\n","\n","### 목표 : 독일어를 영어로 번역하는 모델 만들기\n","독일어 문장을 입력하면 영어로 번역해주는 모델을 seq2seq로 구현해봅시다"],"metadata":{"id":"14MthA8WYQev"}},{"cell_type":"code","source":["!pip install -U torchtext==0.6.0"],"metadata":{"id":"7PbwGzED6TIV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725896199323,"user_tz":-540,"elapsed":8880,"user":{"displayName":"조하늘","userId":"17891951100765145293"}},"outputId":"9d7ea9ac-f722-4493-e05d-23b1035b2443"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.32.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.4.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.26.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n"]}]},{"cell_type":"code","source":["!python -m spacy download en\n","!python -m spacy download de"],"metadata":{"id":"DPKSSHzQ6Uoh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725896226997,"user_tz":-540,"elapsed":27679,"user":{"displayName":"조하늘","userId":"17891951100765145293"}},"outputId":"24bd777d-27ee-4f73-bfd6-2feb9120921a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n","full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n","Collecting en-core-web-sm==3.7.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.6)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (71.0.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.0)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n","\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n","full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n","Collecting de-core-news-sm==3.7.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.6)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.8.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (71.0.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.20.1)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.8.0)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.19.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.16.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('de_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import random\n","import time\n","import math\n","import spacy\n","from torchtext.datasets import TranslationDataset\n","from torchtext.data import Field, BucketIterator\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim"],"metadata":{"id":"MJWiAS2yWutF","executionInfo":{"status":"ok","timestamp":1725896232174,"user_tz":-540,"elapsed":5211,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### Tokenizers\n","\n","- 문장의 토큰화, 태깅 등의 전처리를 수행하기 위해 `spaCy` 라이브러리에서 영어와 독일어 전처리 모듈을 설치해줍니다.\n","- 두 언어의 문장이 주어졌기 때문에 영어와 독일어 각각에 대해 전처리해주어야 합니다.\n"],"metadata":{"id":"uHmIKputmJfU"}},{"cell_type":"code","source":["spacy_de = spacy.load('de_core_news_sm')\n","spacy_en = spacy.load('en_core_web_sm')"],"metadata":{"id":"l7ZtI5IXm7EG","executionInfo":{"status":"ok","timestamp":1725896242171,"user_tz":-540,"elapsed":7682,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# 예시\n","result = spacy_en.tokenizer(\"I am a student.\")\n","\n","for i, token in enumerate(result):\n","    print(f\"인덱스 {i}: {token.text}\")"],"metadata":{"id":"co1TC8yv7yrX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725896249120,"user_tz":-540,"elapsed":320,"user":{"displayName":"조하늘","userId":"17891951100765145293"}},"outputId":"77ebe6dc-8754-419b-d70f-045012a32d61"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["인덱스 0: I\n","인덱스 1: am\n","인덱스 2: a\n","인덱스 3: student\n","인덱스 4: .\n"]}]},{"cell_type":"markdown","source":["필드(field) 라이브러리를 이용해 데이터셋에 대한 구체적인 전처리 내용을 명시해줍니다."],"metadata":{"id":"lEGmP9Uk8gQG"}},{"cell_type":"code","source":["#===================================================\n","# 💡 토큰화 결과가 list로 반환될 수 있도록 return 결과값을 채워주세요\n","# seq2sxeq 논문에 의하면, input 단어의 순서를 바꾸면 최적화가 더 쉬워져 성능이 좋아진다고 합니다.\n","# 💡 독일어 토큰화 결과가 역순으로 return될 수 있도록 반영해주세요!\n","#===================================================\n","def tokenize_de(text):\n","    return\n","\n","def tokenize_en(text):\n","    return"],"metadata":{"id":"uMjoI1XE7tGF","executionInfo":{"status":"ok","timestamp":1725896250538,"user_tz":-540,"elapsed":293,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["필드(field) 라이브러리를 이용해 데이터셋에 대한 구체적인 전처리 내용을 명시해줍니다."],"metadata":{"id":"z3wGw1nPnpMd"}},{"cell_type":"code","source":["# 독일어\n","SRC = Field(tokenize= tokenize_de, init_token = '<sos>', eos_token = '<eos>', lower = True)\n","# 영어\n","TRG = Field(tokenize= tokenize_en, init_token = '<sos>', eos_token = '<eos>', lower = True)"],"metadata":{"id":"ubKI59GPpQ1f","executionInfo":{"status":"ok","timestamp":1725896251988,"user_tz":-540,"elapsed":324,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### 데이터 불러오기\n","\n","대표적인 영어-독어 번역 데이터셋 Multi30k을 불러옵니다.\n"],"metadata":{"id":"0_ccI6_-8hR3"}},{"cell_type":"code","source":["!git clone https://github.com/multi30k/dataset.git\n","\n","# 압축해제\n","!gunzip /content/dataset/data/task1/raw/train.de.gz\n","!gunzip /content/dataset/data/task1/raw/train.en.gz\n","!gunzip /content/dataset/data/task1/raw/val.de.gz\n","!gunzip /content/dataset/data/task1/raw/val.en.gz\n","!gunzip /content/dataset/data/task1/raw/test_2018_flickr.de.gz\n","!gunzip /content/dataset/data/task1/raw/test_2018_flickr.en.gz"],"metadata":{"id":"mLA5kXAAf2uw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725896254154,"user_tz":-540,"elapsed":1032,"user":{"displayName":"조하늘","userId":"17891951100765145293"}},"outputId":"28d911b7-da2c-4ea5-9f25-c587b57791cd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'dataset' already exists and is not an empty directory.\n","gzip: /content/dataset/data/task1/raw/train.de.gz: No such file or directory\n","gzip: /content/dataset/data/task1/raw/train.en.gz: No such file or directory\n","gzip: /content/dataset/data/task1/raw/val.de.gz: No such file or directory\n","gzip: /content/dataset/data/task1/raw/val.en.gz: No such file or directory\n","gzip: /content/dataset/data/task1/raw/test_2018_flickr.de.gz: No such file or directory\n","gzip: /content/dataset/data/task1/raw/test_2018_flickr.en.gz: No such file or directory\n"]}]},{"cell_type":"code","source":["from torchtext.data import Field\n","\n","SRC = Field(tokenize=str.split, lower=True, init_token='<sos>', eos_token='<eos>', include_lengths=True)\n","TRG = Field(tokenize=str.split, lower=True, init_token='<sos>', eos_token='<eos>', include_lengths=True)\n"],"metadata":{"id":"Sk-srZcIUmH1","executionInfo":{"status":"ok","timestamp":1725896256003,"user_tz":-540,"elapsed":343,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["data_path = '/content/dataset/data/task1/raw/'\n","\n","train_data = TranslationDataset(path=data_path, exts=('train.de', 'train.en'), fields=(SRC, TRG) )\n","val_data = TranslationDataset(path=data_path, exts=('val.de', 'val.en'), fields=(SRC, TRG) )\n","test_data = TranslationDataset(path=data_path, exts=('test_2018_flickr.de', 'test_2018_flickr.en'), fields=(SRC, TRG) )"],"metadata":{"id":"-hNiqQweSj8O","executionInfo":{"status":"ok","timestamp":1725896258966,"user_tz":-540,"elapsed":1488,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(f\"학습 데이터셋(training dataset) 크기: {len(train_data.examples)}개\")\n","print(f\"평가 데이터셋(validation dataset) 크기: {len(val_data.examples)}개\")\n","print(f\"테스트 데이터셋(testing dataset) 크기: {len(test_data.examples)}개\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qxLylN1y-urW","executionInfo":{"status":"ok","timestamp":1725896260607,"user_tz":-540,"elapsed":337,"user":{"displayName":"조하늘","userId":"17891951100765145293"}},"outputId":"2a94c88d-b1ca-46fc-ccb3-2cac1ba0b821"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["학습 데이터셋(training dataset) 크기: 29000개\n","평가 데이터셋(validation dataset) 크기: 1014개\n","테스트 데이터셋(testing dataset) 크기: 1071개\n"]}]},{"cell_type":"code","source":["print(vars(train_data.examples[0]))\n","print(vars(train_data.examples[1]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rpt6l_Xd_AQX","executionInfo":{"status":"ok","timestamp":1725896262249,"user_tz":-540,"elapsed":324,"user":{"displayName":"조하늘","userId":"17891951100765145293"}},"outputId":"447547a6-b505-433f-825b-3eb87e5afdf4"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["{'src': ['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche.'], 'trg': ['two', 'young,', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes.']}\n","{'src': ['mehrere', 'männer', 'mit', 'schutzhelmen', 'bedienen', 'ein', 'antriebsradsystem.'], 'trg': ['several', 'men', 'in', 'hard', 'hats', 'are', 'operating', 'a', 'giant', 'pulley', 'system.']}\n"]}]},{"cell_type":"markdown","source":["- `build_vocab`함수를 이용하여 영어와 독일어의 단어 사전을 생성해줍니다. 이를 통해 각 token이 indexing됩니다\n","- 단, vocabulary는 훈련 데이터셋에 대해서만 만들어져야 합니다.\n","- `min_freq`를 사용하여 최소 2번 이상 나오는 단어들만 사전에 포함되도록 합니다."],"metadata":{"id":"uNoigj40AD_0"}},{"cell_type":"code","source":["SRC.build_vocab(train_data, min_freq = 2)\n","TRG.build_vocab(train_data, min_freq = 2)"],"metadata":{"id":"TfK-pAr_ApLP","executionInfo":{"status":"ok","timestamp":1725896264497,"user_tz":-540,"elapsed":683,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["print(TRG.vocab.stoi[\"abcabc\"]) # 없는 단어: 0\n","print(TRG.vocab.stoi[TRG.pad_token]) # 패딩(padding): 1\n","print(TRG.vocab.stoi[\"\"]) # : 0\n","print(TRG.vocab.stoi[\"\"]) # : 0\n","print(TRG.vocab.stoi[\"hello\"])\n","print(TRG.vocab.stoi[\"world\"])"],"metadata":{"id":"KyaA5P0Mrqaa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725896265856,"user_tz":-540,"elapsed":328,"user":{"displayName":"조하늘","userId":"17891951100765145293"}},"outputId":"b4955355-87a9-46e9-d228-0e57bd6a8f77"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n","0\n","0\n","5039\n","2798\n"]}]},{"cell_type":"markdown","source":["- 시퀀스 데이터는 각 문장의 길이가 다를 수 있습니다.\n","- `BucketIterator는` 유사한 길이를 가진 샘플들을 같은 배치에 묶어주는 역할을 하기 때문에, 고정된 길이로 맞추기 위한 패딩의 양을 최소화할 수 있습니다."],"metadata":{"id":"GmHXb1phBXJN"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","BATCH_SIZE = 128\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, val_data, test_data),\n","    batch_size = BATCH_SIZE,\n","    device = device\n",")"],"metadata":{"id":"uazI6xuv8rDH","executionInfo":{"status":"ok","timestamp":1725896687917,"user_tz":-540,"elapsed":357,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["- 첫 번째 배치를 출력한 결과, [sequence length, batch size]라는 tensor가 생성됩니다\n","- `sequence length`는 해당 배치 내에서 가장 긴 문장의 길이를 의미하며, 이보다 짧은 문장은 <pad> token으로 채워집니다.\n","- 편의상 transpose한 뒤, 첫 번째와 두 번째 문장의 텐서를 출력하면, 특정 단어에 대응하는 인덱스가 출력되는 것을 알 수 있습니다.\n"],"metadata":{"id":"Z154iai8Czsr"}},{"cell_type":"code","source":["for i, batch in enumerate(train_iterator):\n","    src = batch.src\n","    trg = batch.trg\n","\n","    # Check if src is a tuple and print shapes accordingly\n","    if isinstance(src, tuple):\n","        print(f\"첫 번째 배치의 text 크기:\")\n","        for j, s in enumerate(src):\n","            print(f\"  src[{j}] shape: {s.shape}\")\n","    else:\n","        print(f\"첫 번째 배치의 text 크기: {src.shape}\")\n","\n","    src = src[0].transpose(1,0) # Access the first element of the tuple if it is one\n","    print(src[0])\n","    print(src[1])\n","\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qsOiNHjIfG-V","executionInfo":{"status":"ok","timestamp":1725897144569,"user_tz":-540,"elapsed":316,"user":{"displayName":"조하늘","userId":"17891951100765145293"}},"outputId":"8cee4f91-170e-472d-9e14-048f497ae901"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["첫 번째 배치의 text 크기:\n","  src[0] shape: torch.Size([27, 128])\n","  src[1] shape: torch.Size([128])\n","tensor([   2,    4,   30,   66,   20,   12, 7718,    3,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1])\n","tensor([   2,    4,   11,    6,  199, 8748,   66,   20,    5,  294,  234,  978,\n","          32,    4,  228,   11,  443,    3,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1])\n"]}]},{"cell_type":"markdown","source":["### Building the Seq2Seq with LSTM Model\n","\n","- seq2seq 이해를 위한 과제이니, 아래를 참고하여 작성해도 무방합니다 :)\n","\n","\n","https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/Sequence_to_Sequence_with_LSTM_Tutorial.ipynb"],"metadata":{"id":"51xSGy35XLvG"}},{"cell_type":"markdown","source":["### Encoder"],"metadata":{"id":"i9WWS97vYnSb"}},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n","        super().__init__()\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout)\n","        self.hid_dim = hidden_dim\n","        self.n_layers = n_layers\n","\n","    def forward(self, src):\n","        embedded = self.embedding(src)\n","        output, (hidden, cell) = self.rnn(embedded)\n","        return output, hidden, cell"],"metadata":{"id":"jJ4QRlItZeET","executionInfo":{"status":"ok","timestamp":1725897157264,"user_tz":-540,"elapsed":310,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["### Decoder"],"metadata":{"id":"ZrQoLPg-Ype1"}},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout):\n","        super().__init__()\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout)\n","        self.fc_out = nn.Linear(hidden_dim, output_dim)\n","        self.hid_dim = hidden_dim\n","        self.n_layers = n_layers\n","\n","    def forward(self, input, hidden, cell):\n","        embedded = self.embedding(input)\n","        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n","        prediction = self.fc_out(output)\n","        return prediction, hidden, cell"],"metadata":{"id":"Rr503e8jY9aJ","executionInfo":{"status":"ok","timestamp":1725897158548,"user_tz":-540,"elapsed":4,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["### Seq2Seq"],"metadata":{"id":"NNsTqRamcfPg"}},{"cell_type":"code","source":["class Seq2Seq(nn.Module):\n","\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","        assert encoder.hid_dim == decoder.hid_dim, \\\n","            \"Hidden dimensions of encoder and decoder must be equal!\"\n","        assert encoder.n_layers == decoder.n_layers, \\\n","            \"Encoder and decoder must have equal number of layers!\"\n","\n","    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n","\n","        #src = [src len, batch size]\n","        #trg = [trg len, batch size]\n","        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n","\n","        batch_size = trg.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","\n","        hidden, cell = self.encoder(src)\n","\n","        #=========================================#\n","        # 💡trg를 사용하여 decoder에 입력할 첫번째 input을 설정해주세요\n","        #=========================================#\n","        input = trg[0, :]\n","\n","        for t in range(1, trg_len):\n","\n","            output, hidden, cell = self.decoder(input, hidden, cell)\n","\n","            outputs[t] = output\n","\n","            # predictions들 중에 가장 잘 예측된 token 추출\n","            best_guess = output.argmax(1) # [batch size]\n","\n","            input = trg[t] if random.random() < teacher_forcing_ratio else best_guess\n","\n","        return outputs"],"metadata":{"id":"Ik28Umx6gAPW","executionInfo":{"status":"ok","timestamp":1725897159736,"user_tz":-540,"elapsed":5,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["### **Q. 위 코드에서는 매 시점마다 확률이 가장 높은 다음 단어를 선택하는 Greedy decoding  방식이 사용됩니다. 이런 방법을 채택할 경우 발생할 수 있는 문제점은 무엇일지 작성해주세요.**\n","\n","\n","```python\n","\n","# predictions들 중에 가장 잘 예측된 token 추출\n","best_guess = output.argmax(1) # [batch size]\n","\n","```\n","\n","\n","➡️  Greedy decoding은 동일한 입력에 대해 매우 유사한 출력을 생성하는 경향이 있어 다양한 출력이 필요하거나 가능성이 있는 경우에는 문제가 될 수 있다. 또한 긴 문서 생성시 초기 선택이 큰 영향을 미칠 수 있다는 위험이 있다."],"metadata":{"id":"bfKrIZ63jkVF"}},{"cell_type":"markdown","source":["### Train"],"metadata":{"id":"EHk36-bkh055"}},{"cell_type":"code","source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","ENC_EMB_DIM = 256\n","DEC_EMB_DIM = 256\n","HID_DIM = 512\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n","\n","model = Seq2Seq(enc, dec, device).to(device)"],"metadata":{"id":"Xj33q4Izh3aB","executionInfo":{"status":"ok","timestamp":1725897162639,"user_tz":-540,"elapsed":313,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["모델 초기 가중치 값은 논문의 내용대로 U(−0.08,0.08)의 연속균등분포로부터 얻습니다."],"metadata":{"id":"uoFprkiyh5vm"}},{"cell_type":"code","source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        nn.init.uniform_(param.data, -0.08, 0.08)\n","\n","model.apply(init_weights)"],"metadata":{"id":"-oLZ0jXyh4zG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725897164714,"user_tz":-540,"elapsed":699,"user":{"displayName":"조하늘","userId":"17891951100765145293"}},"outputId":"3f237c88-47e5-4b3f-a4b2-4495c3aef0d3"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(9597, 256)\n","    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(7704, 256)\n","    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n","    (fc_out): Linear(in_features=512, out_features=7704, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# Encoder와 Decoder 인스턴스 생성\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n","\n","# Seq2Seq 인스턴스 생성\n","model = Seq2Seq(enc, dec, device).to(device)\n","\n","# 모델 파라미터 확인\n","print(list(model.parameters()))  # 파라미터가 비어 있지 않은지 확인\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kwl_-_VdZHKD","executionInfo":{"status":"ok","timestamp":1725897237087,"user_tz":-540,"elapsed":635,"user":{"displayName":"조하늘","userId":"17891951100765145293"}},"outputId":"1c0733ce-385d-4bcc-993b-791bef3a9777"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["[Parameter containing:\n","tensor([[-0.4740,  0.2311, -1.7219,  ...,  0.3498,  1.4974, -0.1825],\n","        [ 0.5892, -0.5552,  0.1837,  ..., -0.4605,  0.4159, -0.2635],\n","        [-0.3329,  0.2747,  1.2537,  ..., -0.4542, -0.0423,  0.7083],\n","        ...,\n","        [ 2.0496,  1.3803,  0.6503,  ..., -0.1232, -0.3691, -0.5854],\n","        [-0.3983, -0.5070, -0.7762,  ...,  0.0700, -0.3778,  0.5729],\n","        [-1.8195, -2.2578, -0.4452,  ...,  2.1176, -0.4223, -0.2977]],\n","       requires_grad=True), Parameter containing:\n","tensor([[-0.0332, -0.0402,  0.0314,  ..., -0.0163,  0.0123,  0.0116],\n","        [-0.0102,  0.0336, -0.0440,  ..., -0.0390, -0.0229, -0.0411],\n","        [ 0.0012, -0.0441,  0.0112,  ..., -0.0262,  0.0207, -0.0387],\n","        ...,\n","        [ 0.0090, -0.0316,  0.0351,  ..., -0.0195,  0.0141,  0.0271],\n","        [ 0.0288,  0.0400, -0.0120,  ..., -0.0410,  0.0361,  0.0248],\n","        [-0.0432,  0.0376, -0.0254,  ..., -0.0031, -0.0037, -0.0257]],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.0218,  0.0167, -0.0306,  ..., -0.0056, -0.0016,  0.0217],\n","        [-0.0243, -0.0098,  0.0348,  ...,  0.0082, -0.0434, -0.0165],\n","        [ 0.0015,  0.0334,  0.0280,  ...,  0.0438, -0.0192,  0.0316],\n","        ...,\n","        [-0.0035,  0.0204,  0.0063,  ...,  0.0313, -0.0282,  0.0320],\n","        [-0.0003, -0.0423, -0.0162,  ...,  0.0372, -0.0356, -0.0065],\n","        [ 0.0162, -0.0329,  0.0117,  ...,  0.0032, -0.0214,  0.0274]],\n","       requires_grad=True), Parameter containing:\n","tensor([ 0.0011,  0.0160, -0.0348,  ...,  0.0125, -0.0020, -0.0407],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0394, -0.0329, -0.0140,  ...,  0.0430, -0.0242,  0.0074],\n","       requires_grad=True), Parameter containing:\n","tensor([[-0.0217, -0.0157,  0.0329,  ...,  0.0022, -0.0344,  0.0128],\n","        [ 0.0367,  0.0009, -0.0083,  ..., -0.0158, -0.0053,  0.0153],\n","        [-0.0213, -0.0047, -0.0279,  ...,  0.0296,  0.0018, -0.0374],\n","        ...,\n","        [-0.0365,  0.0021, -0.0106,  ..., -0.0250,  0.0342, -0.0229],\n","        [-0.0187,  0.0266,  0.0397,  ...,  0.0279, -0.0049, -0.0136],\n","        [-0.0332,  0.0237,  0.0228,  ..., -0.0281, -0.0436, -0.0148]],\n","       requires_grad=True), Parameter containing:\n","tensor([[-0.0155,  0.0261,  0.0413,  ...,  0.0171, -0.0252,  0.0353],\n","        [ 0.0182,  0.0384,  0.0143,  ...,  0.0193, -0.0021,  0.0301],\n","        [ 0.0122,  0.0069, -0.0107,  ...,  0.0395,  0.0173,  0.0316],\n","        ...,\n","        [ 0.0108, -0.0168,  0.0332,  ...,  0.0413, -0.0140, -0.0334],\n","        [-0.0243,  0.0098, -0.0431,  ..., -0.0278,  0.0127,  0.0255],\n","        [-0.0276,  0.0290, -0.0303,  ..., -0.0419, -0.0430, -0.0400]],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0179, -0.0178,  0.0430,  ...,  0.0347, -0.0404, -0.0038],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0280,  0.0331, -0.0425,  ...,  0.0131, -0.0166,  0.0280],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.1067, -0.2040, -1.2653,  ..., -0.1135, -1.4821, -0.1240],\n","        [ 1.4831, -0.1124,  2.1844,  ...,  0.9042, -1.7567,  0.3762],\n","        [ 0.7794,  0.0358,  1.8495,  ...,  0.4334,  1.5475, -0.3912],\n","        ...,\n","        [-0.6464, -0.2196, -0.0400,  ..., -1.2297, -0.6712, -0.2986],\n","        [-1.3864,  0.7375,  0.4863,  ..., -0.4760, -1.5117, -0.6360],\n","        [ 1.7566,  0.8516, -0.0149,  ..., -0.8461, -0.5277, -0.1516]],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.0301,  0.0053, -0.0156,  ...,  0.0341, -0.0052,  0.0352],\n","        [-0.0196,  0.0356,  0.0181,  ...,  0.0199, -0.0016, -0.0102],\n","        [ 0.0346,  0.0422, -0.0383,  ..., -0.0141,  0.0288, -0.0080],\n","        ...,\n","        [-0.0079,  0.0211,  0.0420,  ...,  0.0050,  0.0400,  0.0437],\n","        [-0.0421,  0.0286,  0.0236,  ...,  0.0063,  0.0081, -0.0088],\n","        [-0.0423, -0.0095,  0.0385,  ..., -0.0097, -0.0388, -0.0137]],\n","       requires_grad=True), Parameter containing:\n","tensor([[-0.0366, -0.0441, -0.0007,  ...,  0.0278, -0.0173, -0.0161],\n","        [-0.0314, -0.0358, -0.0206,  ..., -0.0054, -0.0017, -0.0199],\n","        [-0.0194, -0.0197,  0.0198,  ..., -0.0084, -0.0027, -0.0211],\n","        ...,\n","        [-0.0421, -0.0082,  0.0201,  ..., -0.0013,  0.0003,  0.0162],\n","        [-0.0407, -0.0163,  0.0010,  ...,  0.0441,  0.0375,  0.0379],\n","        [-0.0193, -0.0155,  0.0439,  ..., -0.0158, -0.0223, -0.0230]],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0145, -0.0356, -0.0178,  ...,  0.0064, -0.0251,  0.0061],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0095,  0.0199,  0.0297,  ...,  0.0405, -0.0431,  0.0013],\n","       requires_grad=True), Parameter containing:\n","tensor([[-0.0282,  0.0163, -0.0038,  ..., -0.0093,  0.0272,  0.0419],\n","        [-0.0346,  0.0155, -0.0334,  ...,  0.0411, -0.0006,  0.0306],\n","        [-0.0066,  0.0303,  0.0253,  ...,  0.0360, -0.0095, -0.0025],\n","        ...,\n","        [ 0.0261,  0.0068, -0.0088,  ..., -0.0303, -0.0004,  0.0137],\n","        [ 0.0425, -0.0125, -0.0171,  ...,  0.0073, -0.0381,  0.0024],\n","        [ 0.0148, -0.0415,  0.0319,  ..., -0.0268,  0.0398,  0.0051]],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 0.0374,  0.0316,  0.0155,  ..., -0.0069,  0.0106,  0.0437],\n","        [-0.0120, -0.0247, -0.0316,  ..., -0.0238, -0.0142,  0.0292],\n","        [ 0.0033,  0.0304, -0.0214,  ..., -0.0201,  0.0023, -0.0404],\n","        ...,\n","        [ 0.0126, -0.0110,  0.0042,  ...,  0.0168,  0.0108,  0.0396],\n","        [ 0.0414,  0.0312,  0.0166,  ..., -0.0203,  0.0068, -0.0167],\n","        [-0.0121,  0.0327, -0.0214,  ...,  0.0352,  0.0340, -0.0308]],\n","       requires_grad=True), Parameter containing:\n","tensor([ 0.0094,  0.0324,  0.0065,  ..., -0.0191, -0.0110, -0.0381],\n","       requires_grad=True), Parameter containing:\n","tensor([-0.0206,  0.0063, -0.0117,  ..., -0.0355, -0.0321, -0.0018],\n","       requires_grad=True), Parameter containing:\n","tensor([[ 3.7533e-02,  1.2984e-02,  7.0163e-03,  ...,  1.3548e-02,\n","         -2.5905e-02,  2.6246e-02],\n","        [ 4.3707e-02, -3.1587e-02, -1.9795e-02,  ..., -1.5256e-02,\n","          2.4828e-02,  2.5267e-02],\n","        [-6.9751e-04, -4.6843e-03, -1.5271e-02,  ..., -2.3619e-02,\n","          5.7645e-03,  4.0293e-02],\n","        ...,\n","        [-2.4149e-02, -8.9110e-03,  3.8441e-02,  ..., -3.1315e-02,\n","         -1.3094e-03,  4.7589e-03],\n","        [-3.0124e-02,  2.2600e-02,  2.1521e-03,  ...,  3.3170e-02,\n","         -2.8667e-02,  4.6631e-03],\n","        [-3.6897e-02,  2.0069e-02, -5.5307e-05,  ...,  2.1534e-02,\n","          2.0924e-03,  3.9468e-02]], requires_grad=True), Parameter containing:\n","tensor([ 0.0276, -0.0094, -0.0440,  ..., -0.0077, -0.0287,  0.0423],\n","       requires_grad=True)]\n"]}]},{"cell_type":"code","source":["import torch.optim as optim\n","\n","optimizer = optim.Adam(model.parameters())\n","\n","# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n","TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n","criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"],"metadata":{"id":"TpKWiiBIF5NA","executionInfo":{"status":"ok","timestamp":1725897243180,"user_tz":-540,"elapsed":1081,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["### Evaluate"],"metadata":{"id":"veJrgUHBjRVa"}},{"cell_type":"code","source":["def train(model, iterator, optimizer, criterion, clip):\n","\n","    model.train()\n","    epoch_loss = 0\n","\n","    for i, batch in enumerate(iterator):\n","\n","        src = batch.src\n","        trg = batch.trg\n","\n","        optimizer.zero_grad()\n","\n","        output = model(src, trg)\n","\n","        output_dim = output.shape[-1]\n","\n","        output = output[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","\n","        loss = criterion(output, trg)\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)"],"metadata":{"id":"LDfEPQUwFvVG","executionInfo":{"status":"ok","timestamp":1725897245576,"user_tz":-540,"elapsed":353,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, iterator, criterion):\n","\n","    model.eval()\n","\n","    epoch_loss = 0\n","\n","    with torch.no_grad():\n","\n","        for i, batch in enumerate(iterator):\n","\n","            src = batch.src\n","            trg = batch.trg\n","\n","            output = model(src, trg, 0)\n","\n","            output_dim = output.shape[-1]\n","\n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            loss = criterion(output, trg)\n","\n","            epoch_loss += loss.item()\n","\n","    return epoch_loss / len(iterator)"],"metadata":{"id":"O0fOgC3jc8K4","executionInfo":{"status":"ok","timestamp":1725897247448,"user_tz":-540,"elapsed":332,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"id":"5OCHWUhmGORD","executionInfo":{"status":"ok","timestamp":1725897761996,"user_tz":-540,"elapsed":322,"user":{"displayName":"조하늘","userId":"17891951100765145293"}}},"execution_count":63,"outputs":[]}]}