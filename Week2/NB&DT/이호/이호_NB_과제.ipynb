{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian Classifier\n",
    "### Q1. Bayes Rule을 이해하고 Naive  Bayes classifier가 사용하는 사후 확률 계산 과정을 서술하세요.\n",
    "\n",
    "- Bayes Rule:   \n",
    "$P(w_i|x) = \\frac{P(x|w_i)|P(w_i)}{P(x)} = \\frac{P(x|w_i) P(w_i)}{\\Sigma_j P(x|w_j)P(w_j)}$\n",
    "  -\n",
    "  - $P(x|w_i)\\text{: 사후 확률, posterior}\\\\\n",
    "P(x|w_i) \\text{: 가능도/우도, likelihood}\\\\\n",
    "P(w_i) \\text{: 사전 확률, prior}\\\\\n",
    "P(x) \\text{: 증거, evidence}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1.\n",
    "사후확률 : 모든 특성의 우도의 곱 * 사전확률 / 증거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Naive Bayes Classification 방법을 이용해서 다음 생성된 리뷰 데이터에 기반한 감정 분석을 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this great product! It exceeded my expe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Worst purchase I have ever made. Completel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is an average product, nothing special but ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great service and who can help but love this d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terrible experience, I will never buy from thi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I love this great product! It exceeded my expe...  positive\n",
       "1  The Worst purchase I have ever made. Completel...  negative\n",
       "2  It is an average product, nothing special but ...   neutral\n",
       "3  Great service and who can help but love this d...  positive\n",
       "4  Terrible experience, I will never buy from thi...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 데이터 생성\n",
    "data = {\n",
    "    'review': [\n",
    "        'I love this great product! It exceeded my expectations.',\n",
    "        'The Worst purchase I have ever made. Completely useless.',\n",
    "        'It is an average product, nothing special but not terrible either.',\n",
    "        'Great service and who can help but love this design? Highly recommend!',\n",
    "        'Terrible experience, I will never buy from this poor brand again.',\n",
    "        'It’s acceptable, but I expected better service, not just an acceptable one.',\n",
    "        'Absolutely wonderful! I am very satisfied with this great service.',\n",
    "        'The quality is poor and it broke after one use. Terrible enough!',\n",
    "        'Acceptable product for the price, but there are better options out there.',\n",
    "        'Great quality and fast shipping with wonderful service! I love it'\n",
    "    ],\n",
    "    'sentiment': [\n",
    "        'positive', 'negative', 'neutral', 'positive', 'negative',\n",
    "        'neutral', 'positive', 'negative', 'neutral', 'positive',\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트 정의\n",
    "stopwords = ['i', 'my', 'am', 'this', 'it', 'its', 'an', 'a', 'the', 'is', 'are', 'and', 'product', 'service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     love great exceeded expectations\n",
      "1     worst purchase have ever made completely useless\n",
      "2      average nothing special but not terrible either\n",
      "3    great who can help but love design highly reco...\n",
      "4    terrible experience will never buy from poor b...\n",
      "5    acceptable but expected better not just accept...\n",
      "6       absolutely wonderful very satisfied with great\n",
      "7     quality poor broke after one use terrible enough\n",
      "8    acceptable for price but there better options ...\n",
      "9      great quality fast shipping with wonderful love\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 전처리 함수 정의\n",
    "def preprocess_text(text):\n",
    "    # 소문자로 변환\n",
    "    text = text.lower()\n",
    "    # 특수 기호 제거\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # 불용어 제거\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# 모든 리뷰에 대해 전처리 수행\n",
    "df['review'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적인 데이터 전처리가 완료되었습니다!\n",
    "이제부터 직접 나이브 베이지안 분류를 수행해 봅시다.  \n",
    "우리가 분류하고자 하는 문장은 총 두가지 입니다.  \n",
    "전처리가 완료되었다고 치고,   \n",
    "첫번째 문장은 **'love, great, awesome'**,  \n",
    "두번째 문장은 **'terrible, not, never'** 입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 확률 $P(positive), P(negative), P(neutral)$을 구합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(positive) = 0.4\n",
      "P(negative) = 0.3\n",
      "P(neutral) = 0.3\n"
     ]
    }
   ],
   "source": [
    "# 사전 확률 구하는 코드를 작성해주세요.\n",
    "# 클래스별 빈도 계산\n",
    "class_counts = df['sentiment'].value_counts()\n",
    "\n",
    "# 전체 리뷰 수\n",
    "total_reviews = len(df)\n",
    "\n",
    "# 사전 확률 계산\n",
    "P_positive = class_counts['positive'] / total_reviews\n",
    "P_negative = class_counts['negative'] / total_reviews\n",
    "P_neutral = class_counts['neutral'] / total_reviews\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"P(positive) = {P_positive}\")\n",
    "print(f\"P(negative) = {P_negative}\")\n",
    "print(f\"P(neutral) = {P_neutral}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가능도를 구하기 위한 확률들을 계산합니다.  \n",
    "예: 첫번째 문장 분류를 위해서는, $P(love|positive), P(great|positive), P(awesome|positive)\\\\\n",
    "P(love|negative), P(great|negative), P(awesome|negative)\\\\\n",
    "P(love|neutral), P(great|neutral), P(great|neutral)$를 구합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때 CountVectorizer를 사용하여 도출한 단어 벡터를 활용하면 확률들을 간편하게 구할 수 있습니다.  \n",
    "참고: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "review_array = vectorizer.fit_transform(df['review']).toarray()\n",
    "review_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['absolutely', 'acceptable', 'after', 'again', 'average', 'better',\n",
       "       'brand', 'broke', 'but', 'buy', 'can', 'completely', 'design',\n",
       "       'either', 'enough', 'ever', 'exceeded', 'expectations', 'expected',\n",
       "       'experience', 'fast', 'for', 'from', 'great', 'have', 'help',\n",
       "       'highly', 'just', 'love', 'made', 'never', 'not', 'nothing', 'one',\n",
       "       'options', 'out', 'poor', 'price', 'purchase', 'quality',\n",
       "       'recommend', 'satisfied', 'shipping', 'special', 'terrible',\n",
       "       'there', 'use', 'useless', 'very', 'who', 'will', 'with',\n",
       "       'wonderful', 'worst'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 28,\n",
       " 'great': 23,\n",
       " 'exceeded': 16,\n",
       " 'expectations': 17,\n",
       " 'worst': 53,\n",
       " 'purchase': 38,\n",
       " 'have': 24,\n",
       " 'ever': 15,\n",
       " 'made': 29,\n",
       " 'completely': 11,\n",
       " 'useless': 47,\n",
       " 'average': 4,\n",
       " 'nothing': 32,\n",
       " 'special': 43,\n",
       " 'but': 8,\n",
       " 'not': 31,\n",
       " 'terrible': 44,\n",
       " 'either': 13,\n",
       " 'who': 49,\n",
       " 'can': 10,\n",
       " 'help': 25,\n",
       " 'design': 12,\n",
       " 'highly': 26,\n",
       " 'recommend': 40,\n",
       " 'experience': 19,\n",
       " 'will': 50,\n",
       " 'never': 30,\n",
       " 'buy': 9,\n",
       " 'from': 22,\n",
       " 'poor': 36,\n",
       " 'brand': 6,\n",
       " 'again': 3,\n",
       " 'acceptable': 1,\n",
       " 'expected': 18,\n",
       " 'better': 5,\n",
       " 'just': 27,\n",
       " 'one': 33,\n",
       " 'absolutely': 0,\n",
       " 'wonderful': 52,\n",
       " 'very': 48,\n",
       " 'satisfied': 41,\n",
       " 'with': 51,\n",
       " 'quality': 39,\n",
       " 'broke': 7,\n",
       " 'after': 2,\n",
       " 'use': 46,\n",
       " 'enough': 14,\n",
       " 'for': 21,\n",
       " 'price': 37,\n",
       " 'there': 45,\n",
       " 'options': 34,\n",
       " 'out': 35,\n",
       " 'fast': 20,\n",
       " 'shipping': 42}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>average</th>\n",
       "      <th>better</th>\n",
       "      <th>brand</th>\n",
       "      <th>broke</th>\n",
       "      <th>but</th>\n",
       "      <th>...</th>\n",
       "      <th>terrible</th>\n",
       "      <th>there</th>\n",
       "      <th>use</th>\n",
       "      <th>useless</th>\n",
       "      <th>very</th>\n",
       "      <th>who</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  absolutely  acceptable  after  again  average  better  brand  \\\n",
       "0  positive           0           0      0      0        0       0      0   \n",
       "1  negative           0           0      0      0        0       0      0   \n",
       "2   neutral           0           0      0      0        1       0      0   \n",
       "3  positive           0           0      0      0        0       0      0   \n",
       "4  negative           0           0      0      1        0       0      1   \n",
       "5   neutral           0           2      0      0        0       1      0   \n",
       "6  positive           1           0      0      0        0       0      0   \n",
       "7  negative           0           0      1      0        0       0      0   \n",
       "8   neutral           0           1      0      0        0       1      0   \n",
       "9  positive           0           0      0      0        0       0      0   \n",
       "\n",
       "   broke  but  ...  terrible  there  use  useless  very  who  will  with  \\\n",
       "0      0    0  ...         0      0    0        0     0    0     0     0   \n",
       "1      0    0  ...         0      0    0        1     0    0     0     0   \n",
       "2      0    1  ...         1      0    0        0     0    0     0     0   \n",
       "3      0    1  ...         0      0    0        0     0    1     0     0   \n",
       "4      0    0  ...         1      0    0        0     0    0     1     0   \n",
       "5      0    1  ...         0      0    0        0     0    0     0     0   \n",
       "6      0    0  ...         0      0    0        0     1    0     0     1   \n",
       "7      1    0  ...         1      0    1        0     0    0     0     0   \n",
       "8      0    1  ...         0      2    0        0     0    0     0     0   \n",
       "9      0    0  ...         0      0    0        0     0    0     0     1   \n",
       "\n",
       "   wonderful  worst  \n",
       "0          0      0  \n",
       "1          0      1  \n",
       "2          0      0  \n",
       "3          0      0  \n",
       "4          0      0  \n",
       "5          0      0  \n",
       "6          1      0  \n",
       "7          0      0  \n",
       "8          0      0  \n",
       "9          1      0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_matrix = pd.DataFrame(review_array, columns = vectorizer.get_feature_names_out())\n",
    "frequency_matrix = pd.concat([df['sentiment'], frequency_matrix], axis=1)\n",
    "frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(love|positive) = 0.05\n",
      "P(love|negative) = 0.01282051282051282\n",
      "P(love|neutral) = 0.01282051282051282\n",
      "\n",
      "P(great|positive) = 0.0625\n",
      "P(great|negative) = 0.01282051282051282\n",
      "P(great|neutral) = 0.01282051282051282\n",
      "\n",
      "P(awesome|positive) = 0.0125\n",
      "P(awesome|negative) = 0.01282051282051282\n",
      "P(awesome|neutral) = 0.01282051282051282\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# 리뷰 데이터를 단어 벡터로 변환\n",
    "vectorizer = CountVectorizer()\n",
    "review_array = vectorizer.fit_transform(df['review']).toarray()\n",
    "\n",
    "# 단어 리스트 추출\n",
    "words = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 단어 빈도 테이블 생성\n",
    "frequency_matrix = pd.DataFrame(review_array, columns=words)\n",
    "frequency_matrix = pd.concat([df['sentiment'], frequency_matrix], axis=1)\n",
    "\n",
    "# 각 단어의 조건부 확률을 구하는 함수\n",
    "def calculate_conditional_probabilities(frequency_matrix, word, sentiment_class):\n",
    "    # 해당 클래스의 빈도 계산\n",
    "    class_df = frequency_matrix[frequency_matrix['sentiment'] == sentiment_class]\n",
    "    \n",
    "    # 해당 클래스에서의 단어 빈도 합계\n",
    "    if word in class_df.columns:\n",
    "        class_word_sum = class_df[word].sum()\n",
    "    else:\n",
    "        class_word_sum = 0  # 단어가 해당 클래스에 없을 경우 0으로 설정\n",
    "    \n",
    "    # 해당 클래스 내 모든 단어 빈도 합계\n",
    "    class_total_word_sum = class_df[words].sum().sum()\n",
    "    \n",
    "    # 라플라스 스무딩을 적용하여 조건부 확률 계산\n",
    "    conditional_probability = (class_word_sum + 1) / (class_total_word_sum + len(words))\n",
    "    return conditional_probability\n",
    "\n",
    "# 첫 번째 문장의 단어들에 대한 조건부 확률 계산\n",
    "words_to_check = ['love', 'great', 'awesome']\n",
    "\n",
    "# 각 단어의 조건부 확률을 계산\n",
    "for word in words_to_check:\n",
    "    P_word_pos = calculate_conditional_probabilities(frequency_matrix, word, 'positive')\n",
    "    P_word_neg = calculate_conditional_probabilities(frequency_matrix, word, 'negative')\n",
    "    P_word_neu = calculate_conditional_probabilities(frequency_matrix, word, 'neutral')\n",
    "    \n",
    "    print(f\"P({word}|positive) = {P_word_pos}\")\n",
    "    print(f\"P({word}|negative) = {P_word_neg}\")\n",
    "    print(f\"P({word}|neutral) = {P_word_neu}\")\n",
    "    print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "독립성 가정을 이용하여 가능도(likelihood)를 구합니다.  \n",
    "첫번째 문장 예시: $P(love, great, awesome|positive), P(love, great, awesome|negative), P(love, great, awesome|neutral)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(love, great, awesome | positive) = 3.906250000000001e-05\n",
      "P(love, great, awesome | negative) = 2.107250627960687e-06\n",
      "P(love, great, awesome | neutral) = 2.107250627960687e-06\n"
     ]
    }
   ],
   "source": [
    "# 가능도 구하는 코드를 작성해주세요.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# 리뷰 데이터를 단어 벡터로 변환\n",
    "vectorizer = CountVectorizer()\n",
    "review_array = vectorizer.fit_transform(df['review']).toarray()\n",
    "\n",
    "# 단어 리스트 추출\n",
    "words = vectorizer.get_feature_names_out()\n",
    "\n",
    "# 단어 빈도 테이블 생성\n",
    "frequency_matrix = pd.DataFrame(review_array, columns=words)\n",
    "frequency_matrix = pd.concat([df['sentiment'], frequency_matrix], axis=1)\n",
    "\n",
    "# 각 단어의 조건부 확률을 구하는 함수\n",
    "def calculate_conditional_probabilities(frequency_matrix, word, sentiment_class):\n",
    "    # 해당 클래스의 빈도 계산\n",
    "    class_df = frequency_matrix[frequency_matrix['sentiment'] == sentiment_class]\n",
    "    \n",
    "    # 해당 클래스에서의 단어 빈도 합계\n",
    "    if word in class_df.columns:\n",
    "        class_word_sum = class_df[word].sum()\n",
    "    else:\n",
    "        class_word_sum = 0  # 단어가 해당 클래스에 없을 경우 0으로 설정\n",
    "    \n",
    "    # 해당 클래스 내 모든 단어 빈도 합계\n",
    "    class_total_word_sum = class_df[words].sum().sum()\n",
    "    \n",
    "    # 라플라스 스무딩을 적용하여 조건부 확률 계산\n",
    "    conditional_probability = (class_word_sum + 1) / (class_total_word_sum + len(words))\n",
    "    return conditional_probability\n",
    "\n",
    "# Naive Bayes 독립성 가정을 이용한 가능도 계산 함수\n",
    "def calculate_likelihood(words_to_check, sentiment_class):\n",
    "    likelihood = 1.0\n",
    "    for word in words_to_check:\n",
    "        likelihood *= calculate_conditional_probabilities(frequency_matrix, word, sentiment_class)\n",
    "    return likelihood\n",
    "\n",
    "# 첫 번째 문장의 단어들에 대한 가능도 계산\n",
    "words_to_check = ['love', 'great', 'awesome']\n",
    "\n",
    "# 각 클래스에 대한 가능도 계산\n",
    "likelihood_pos = calculate_likelihood(words_to_check, 'positive')\n",
    "likelihood_neg = calculate_likelihood(words_to_check, 'negative')\n",
    "likelihood_neu = calculate_likelihood(words_to_check, 'neutral')\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"P(love, great, awesome | positive) = {likelihood_pos}\")\n",
    "print(f\"P(love, great, awesome | negative) = {likelihood_neg}\")\n",
    "print(f\"P(love, great, awesome | neutral) = {likelihood_neu}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 구한 사전 확률과 가능도를 이용하여 타겟 문장이 positive, negative, neutral일 확률을 구하고 최종적으로 어떤 감성일지 분석해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(positive | target_review1) = 0.9251391943105787\n",
      "P(negative | target_review1) = 0.0374304028447106\n",
      "P(neutral | target_review1) = 0.0374304028447106\n",
      "P(positive | target_review2) = 0.09336884305364711\n",
      "P(negative | target_review2) = 0.4533155784731765\n",
      "P(neutral | target_review2) = 0.4533155784731765\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 사전 확률 구하기\n",
    "def calculate_prior_probability(sentiment_class):\n",
    "    class_count = frequency_matrix[frequency_matrix['sentiment'] == sentiment_class].shape[0]\n",
    "    total_count = frequency_matrix.shape[0]\n",
    "    return class_count / total_count\n",
    "\n",
    "# Naive Bayes 독립성 가정을 이용한 가능도 계산 함수\n",
    "def calculate_likelihood(words_to_check, sentiment_class):\n",
    "    likelihood = 1.0\n",
    "    for word in words_to_check:\n",
    "        likelihood *= calculate_conditional_probabilities(frequency_matrix, word, sentiment_class)\n",
    "    return likelihood\n",
    "\n",
    "# 전체 확률 P(data)를 구하는 함수\n",
    "def calculate_total_probability(words_to_check):\n",
    "    total_probability = 0\n",
    "    for sentiment_class in ['positive', 'negative', 'neutral']:\n",
    "        prior = calculate_prior_probability(sentiment_class)\n",
    "        likelihood = calculate_likelihood(words_to_check, sentiment_class)\n",
    "        total_probability += prior * likelihood\n",
    "    return total_probability\n",
    "\n",
    "# 사후 확률 P(class | data) 계산 함수\n",
    "def calculate_posterior(words_to_check, sentiment_class):\n",
    "    prior = calculate_prior_probability(sentiment_class)\n",
    "    likelihood = calculate_likelihood(words_to_check, sentiment_class)\n",
    "    total_prob = calculate_total_probability(words_to_check)\n",
    "    posterior = (prior * likelihood) / total_prob\n",
    "    return posterior\n",
    "\n",
    "# 첫 번째 문장의 단어들\n",
    "words_to_check_1 = ['love', 'great', 'awesome']\n",
    "\n",
    "# 첫 번째 문장에 대한 각 클래스의 사후 확률 계산\n",
    "P_pos_1 = calculate_posterior(words_to_check_1, 'positive')\n",
    "P_neg_1 = calculate_posterior(words_to_check_1, 'negative')\n",
    "P_neu_1 = calculate_posterior(words_to_check_1, 'neutral')\n",
    "\n",
    "print(f\"P(positive | target_review1) = {P_pos_1}\")\n",
    "print(f\"P(negative | target_review1) = {P_neg_1}\")\n",
    "print(f\"P(neutral | target_review1) = {P_neu_1}\")\n",
    "\n",
    "# 두 번째 문장의 단어들\n",
    "words_to_check_2 = ['terrible', 'not', 'never']\n",
    "\n",
    "# 두 번째 문장에 대한 각 클래스의 사후 확률 계산\n",
    "P_pos_2 = calculate_posterior(words_to_check_2, 'positive')\n",
    "P_neg_2 = calculate_posterior(words_to_check_2, 'negative')\n",
    "P_neu_2 = calculate_posterior(words_to_check_2, 'neutral')\n",
    "\n",
    "print(f\"P(positive | target_review2) = {P_pos_2}\")\n",
    "print(f\"P(negative | target_review2) = {P_neg_2}\")\n",
    "print(f\"P(neutral | target_review2) = {P_neu_2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-1.   \n",
    "Target review1의 분류 결과:   positive가 92퍼센트\n",
    "Target review2의 분류 결과:   Negetive, neutral이 각각 45퍼센트 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2-2. 나이브 베이지안 기반 확률을 구하는 과정에서 어떤 문제점을 발견할 수 있었나요? 그리고 그 문제를 해결하기 위한 방법에 대해 간략하게 조사 및 서술해 주세요. (힌트: Laplace smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-2. 특정 단어(awesome)이 관측되지 않아 오류가 발생했다. 라플라스 스무딩을 통해 분자를 1로 만들어주어 그러한 부작용을 없앤다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
